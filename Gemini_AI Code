# @title Market Intelligence Bot { display-mode: "form" }
import gradio as gr
import google.generativeai as genai
# Used to securely store your API key
from google.colab import userdata
from io import StringIO
import pandas as pd

#get the api key from secrets
GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')
genai.configure(api_key=GOOGLE_API_KEY)

#select the model to use
model = genai.GenerativeModel('gemini-pro')

#initialize the chat history
chat = model.start_chat(history=[])

import gradio as gr
import google.generativeai as genai
# Used to securely store your API key
from google.colab import userdata

#get the api key from secrets
GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')
genai.configure(api_key=GOOGLE_API_KEY)

#select the model to use
model = genai.GenerativeModel('gemini-pro')

#initialize the chat history
chat = model.start_chat(history=[])

file_name = None

#function remove the first turn of conversation
def remove_chat():
  chat.history = chat.history[2:]
  print("Chat history truncated")
  return True


def get_data(file_path):
  with open(file_path, 'r') as file:
    dataset = file.read()
  prompt_template = f"""You are an assistant bot that helps pricing managers quote a price for specific lanes(lanes are combination of origin and destination pairs) based on the given csv data. \
    The dataset is a document, pricing managers have to check before making quotes to customers. This is the column details of the csv dataset:{column_details}"""

#function(accepts the message from the user and a history of the conversation) to pass the prompt to the model and return the response
def generate_solution(message, gradio_history, temperature, file_path):
    global dataset
    global file_name
    prompt_template = f"""You are an ai assistant that helps in answering queries based on the given csv data. \
    The dataset is a document, that you have to check before making responses. This is the column details of the csv dataset:{column_details}. Please go though it carefully and remember each and every reference. \
    When the user asks a question follow these steps,
    1)Go through the given column details and find the relevant matching columns. 2)Go through the entire dataset and find the matching columns. 3)Using those columns as \
    context, perform necessary calculations or aggregations. 4)Give the output along with the relevant column names. \
    Always give responses from the given dataset only and give descriptive answers. Question: \n{message}\n Answer:"""


    if file_path != file_name:
      with open(file_path, 'r') as file:
        dataset = file.read()
        prompt_template = prompt_template + '\n' + 'Dataset: ' + dataset
      file_name = file_path
      csv_buffer = StringIO(dataset)
      df = pd.read_csv(csv_buffer)
      df.to_csv('dataset.csv', index=False)
    message_tokens = int(str(model.count_tokens(prompt_template)).strip().split(" ")[1])
    if len(chat.history) > 0:
      history_tokens = int(str(model.count_tokens(chat.history)).strip().split(" ")[1])
      while (message_tokens + history_tokens) > 30000:
        remove_chat()
        return "Chat history truncated! Note: The bot might have lost the first few turns of conversation"
        if len(chat.history) == 0:
          break
        history_tokens = int(str(model.count_tokens(chat.history)).strip().split(" ")[1])
    elif message_tokens > 30000:
      return "Prompt too long! Try again with a shorter prompt"
    response = chat.send_message(prompt_template,generation_config=genai.types.GenerationConfig(temperature=temperature))
    return response.text
#Example user-bot conversation: {example_conversation}

gr.ChatInterface(generate_solution,
                 title = "Market Intelligence Bot",
                 retry_btn= None,
                 undo_btn = None,
                 theme='Taithrah/Minimal',
                 additional_inputs=[gr.Slider(0.0, 1.0,step=0.1,label="Temperature",value=0.3), gr.File(file_types=["text"])]
                 ).launch(debug= True, share = True)
